{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax import numpy as jnp\n",
    "import numpy as np\n",
    "import jax\n",
    "from jax.nn import sigmoid\n",
    "import sys\n",
    "import jax.random as random\n",
    "sys.path.append(\"/Users/changjc/workspace/bayesianquilts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsigmoid = lambda x: sigmoid(x) * (1 - sigmoid(x))\n",
    "ddsigmoid = lambda x: sigmoid(x) * (1 - sigmoid(x)) * (1 - 2 * sigmoid(x))\n",
    "\n",
    "\n",
    "#\n",
    "# N x I x K\n",
    "\n",
    "\n",
    "def p_ni(abilities, difficulties, discriminations):  # dimensio\n",
    "    p_cum = sigmoid(discriminations * (abilities - difficulties))\n",
    "    # first partials\n",
    "    dp_cum_dabilities = (p_cum * (1 - p_cum))[\n",
    "        ..., np.newaxis\n",
    "    ] * discriminations[np.newaxis, np.newaxis, :, :, 0]\n",
    "    dp_cum_ddifficulties = (\n",
    "        -(p_cum * (1 - p_cum))[..., np.newaxis, np.newaxis]\n",
    "        * discriminations[np.newaxis, np.newaxis, np.newaxis, ...]\n",
    "    )\n",
    "    dp_cum_ddiscrimintations = (p_cum * (1 - p_cum))[\n",
    "        ..., np.newaxis, np.newaxis, np.newaxis\n",
    "    ] * (abilities - difficulties)[np.newaxis, np.newaxis, np.newaxis, ...]\n",
    "\n",
    "    # second partials\n",
    "    # pure\n",
    "    d2p_cum_dabilities2 = p_cum * (1 - p_cum) * (1 - 2 * p_cum) * discriminations**2\n",
    "    d2p_cum_ddifficulties2 = (\n",
    "        p_cum * (1 - p_cum) * (1 - 2 * p_cum) * discriminations * discriminations**2\n",
    "    )\n",
    "    d2p_cum_ddiscrimintations2 = (\n",
    "        p_cum * (1 - p_cum) * (1 - 2 * p_cum) * (abilities - difficulties) ** 2\n",
    "    )\n",
    "    # mixed\n",
    "    d2p_cum_dabilities_difficulties = (\n",
    "        -p_cum * (1 - p_cum) * (1 - 2 * p_cum) * discriminations**2\n",
    "    )\n",
    "    d2p_cum_dabilities_discriminations = (\n",
    "        p_cum * (1 - p_cum) + p_cum * (1 - p_cum) * (1 - 2 * p_cum) * discriminations**2\n",
    "    )\n",
    "    d2p_cum_ddifficulties_discriminations = -p_cum * (1 - p_cum) - p_cum * (\n",
    "        1 - p_cum\n",
    "    ) * (1 - 2 * p_cum) * discriminations * (abilities - difficulties)\n",
    "\n",
    "    p_cum = jnp.pad(\n",
    "        p_cum, ((0, 0), (0, 0), (1, 0)), constant_values=0\n",
    "    )\n",
    "    p_cum = jnp.pad(\n",
    "        p_cum, ((0, 0), (0, 0), (0, 1)), constant_values=1\n",
    "    )\n",
    "\n",
    "    dp_cum_dabilities = jnp.pad(\n",
    "        dp_cum_dabilities, ((0, 0), (0, 0), (1, 1), (0, 0), (0, 0), (0, 0)), constant_values=0\n",
    "    )\n",
    "    dp_cum_ddifficulties = jnp.pad(\n",
    "        dp_cum_ddifficulties, ((0, 0), (0, 0), (1, 1), (0, 0), (0, 0), (0, 0)), constant_values=0\n",
    "    )\n",
    "    dp_cum_ddiscrimintations = jnp.pad(\n",
    "        dp_cum_ddiscrimintations, ((0, 0), (0, 0), (1, 1), (0, 0), (0, 0), (0, 0)), constant_values=0\n",
    "    )\n",
    "\n",
    "    dp_dabilities = dp_cum_dabilities[:, :, 1:, ...] - dp_cum_dabilities[:, :, :-1, ...]\n",
    "    dp_ddifficulties = dp_cum_ddifficulties[:, :, 1:, ...] - dp_cum_ddifficulties[:, :, :-1, ...]\n",
    "    dp_ddiscrimintations = (\n",
    "        dp_cum_ddiscrimintations[:, :,  1:, ...] - dp_cum_ddiscrimintations[:, :,  :-1, ...]\n",
    "    )\n",
    "\n",
    "    p = p_cum[..., 1:] - p_cum[..., :-1]\n",
    "\n",
    "    # compute derivatives\n",
    "\n",
    "    gradients = {\n",
    "        \"abilities\": dp_dabilities,\n",
    "        \"difficulties\": dp_ddifficulties,\n",
    "        \"discriminations\": dp_ddiscrimintations,\n",
    "    }\n",
    "\n",
    "    hessians = {}\n",
    "\n",
    "    return p, gradients, hessians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "abilities = np.array([0, 0.5, 0.25])[:, np.newaxis, np.newaxis]\n",
    "difficulties = np.array([[0, 1, 2, 3], [-2, 0, 3, 4]])[np.newaxis, ...]\n",
    "discriminations = np.array([1, 2])[np.newaxis, :, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "jnp.pad: pad_width with nd=4 has unsupported shape (6, 2). Valid shapes are (4, 2), (1, 2), (2,), (1,), or ().",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mp_ni\u001b[49m\u001b[43m(\u001b[49m\u001b[43mabilities\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdifficulties\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiscriminations\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 50\u001b[0m, in \u001b[0;36mp_ni\u001b[0;34m(abilities, difficulties, discriminations)\u001b[0m\n\u001b[1;32m     43\u001b[0m p_cum \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mpad(\n\u001b[1;32m     44\u001b[0m     p_cum, ((\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m), (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m), (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m)), constant_values\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     45\u001b[0m )\n\u001b[1;32m     46\u001b[0m p_cum \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mpad(\n\u001b[1;32m     47\u001b[0m     p_cum, ((\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m), (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m), (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)), constant_values\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     48\u001b[0m )\n\u001b[0;32m---> 50\u001b[0m dp_cum_dabilities \u001b[38;5;241m=\u001b[39m \u001b[43mjnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdp_cum_dabilities\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconstant_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\n\u001b[1;32m     52\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m dp_cum_ddifficulties \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mpad(\n\u001b[1;32m     54\u001b[0m     dp_cum_ddifficulties, ((\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m), (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m), (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m), (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m), (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m), (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m)), constant_values\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     55\u001b[0m )\n\u001b[1;32m     56\u001b[0m dp_cum_ddiscrimintations \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mpad(\n\u001b[1;32m     57\u001b[0m     dp_cum_ddiscrimintations, ((\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m), (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m), (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m), (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m), (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m), (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m)), constant_values\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     58\u001b[0m )\n",
      "File \u001b[0;32m~/workspace/autoencirt/env/lib/python3.11/site-packages/jax/_src/numpy/lax_numpy.py:4353\u001b[0m, in \u001b[0;36mpad\u001b[0;34m(array, pad_width, mode, **kwargs)\u001b[0m\n\u001b[1;32m   4237\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Add padding to an array.\u001b[39;00m\n\u001b[1;32m   4238\u001b[0m \n\u001b[1;32m   4239\u001b[0m \u001b[38;5;124;03mJAX implementation of :func:`numpy.pad`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4349\u001b[0m \u001b[38;5;124;03m  Array([-10, -10,   2,   3,   4,  10,  10], dtype=int32)\u001b[39;00m\n\u001b[1;32m   4350\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4352\u001b[0m array \u001b[38;5;241m=\u001b[39m util\u001b[38;5;241m.\u001b[39mensure_arraylike(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpad\u001b[39m\u001b[38;5;124m\"\u001b[39m, array)\n\u001b[0;32m-> 4353\u001b[0m pad_width \u001b[38;5;241m=\u001b[39m \u001b[43m_broadcast_to_pairs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpad_width\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mndim\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpad_width\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4354\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pad_width \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(core\u001b[38;5;241m.\u001b[39mis_dim(p[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;129;01mand\u001b[39;00m core\u001b[38;5;241m.\u001b[39mis_dim(p[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m   4355\u001b[0m                          \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m pad_width):\n\u001b[1;32m   4356\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`pad_width` must be of integral type.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/workspace/autoencirt/env/lib/python3.11/site-packages/jax/_src/numpy/lax_numpy.py:3938\u001b[0m, in \u001b[0;36m_broadcast_to_pairs\u001b[0;34m(nvals, nd, name)\u001b[0m\n\u001b[1;32m   3936\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m((v, v) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(nd))\n\u001b[1;32m   3937\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3938\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjnp.pad: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnd\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m has unsupported shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnvals\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3939\u001b[0m                    \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValid shapes are (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnd\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, 2), (1, 2), (2,), (1,), or ().\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: jnp.pad: pad_width with nd=4 has unsupported shape (6, 2). Valid shapes are (4, 2), (1, 2), (2,), (1,), or ()."
     ]
    }
   ],
   "source": [
    "p_ni(abilities, difficulties, discriminations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.io'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m K \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mautoencirt\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrwa\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m item_text, get_data, to_reverse\n",
      "File \u001b[0;32m~/workspace/autoencirt/autoencirt/__init__.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mirt\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[0;32m~/workspace/autoencirt/autoencirt/irt/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mirt\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m IRTModel\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgrm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GRModel\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfactorizedgrm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FactorizedGRModel\n",
      "File \u001b[0;32m~/workspace/autoencirt/autoencirt/irt/irt.py:2\u001b[0m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbayesianquilts\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BayesianModel\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbayesianquilts\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdense\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dense\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_probability\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msubstrates\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mjax\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distributions \u001b[38;5;28;01mas\u001b[39;00m tfd\n",
      "File \u001b[0;32m~/workspace/bayesianquilts/bayesianquilts/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BayesianModel\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlogistic_bayesianquilt\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LogisticBayesianquilt\n",
      "File \u001b[0;32m~/workspace/bayesianquilts/bayesianquilts/model.py:19\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbayesianquilts\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FactorizedDistributionMoments\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbayesianquilts\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m training_loop\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbayesianquilts\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mminibatch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m minibatch_fit_surrogate_posterior\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mBayesianModel\u001b[39;00m(ABC, nnx\u001b[38;5;241m.\u001b[39mModule):\n",
      "File \u001b[0;32m~/workspace/bayesianquilts/bayesianquilts/util.py:9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01moptax\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mflax\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m unfreeze\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mflax\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtraining\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m checkpoints\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_probability\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msubstrates\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mjax\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf2jax \u001b[38;5;28;01mas\u001b[39;00m tf\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n",
      "File \u001b[0;32m~/workspace/autoencirt/env/lib/python3.11/site-packages/flax/training/checkpoints.py:45\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mjax\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marray_serialization\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mserialization\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     40\u001b[0m   GlobalAsyncCheckpointManager,\n\u001b[1;32m     41\u001b[0m   get_tensorstore_spec,\n\u001b[1;32m     42\u001b[0m )\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mjax\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmultihost_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sync_global_devices\n\u001b[0;32m---> 45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mflax\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config, core, errors, io, serialization, traverse_util\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mflax\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtraining\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m orbax_utils\n\u001b[1;32m     49\u001b[0m _READ_CHECKPOINT_EVENT: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/jax/checkpoint/read/durations_sec\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m~/workspace/autoencirt/env/lib/python3.11/site-packages/flax/io.py:42\u001b[0m\n\u001b[1;32m     39\u001b[0m gfile \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mutil\u001b[38;5;241m.\u001b[39mfind_spec(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtensorflow\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m---> 42\u001b[0m   \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m gfile  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m     44\u001b[0m   io_mode \u001b[38;5;241m=\u001b[39m BackendMode\u001b[38;5;241m.\u001b[39mTF\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.io'"
     ]
    }
   ],
   "source": [
    "K = 10\n",
    "from autoencirt.data.rwa import item_text, get_data, to_reverse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_data = get_data(reorient=True, pandas=True)\n",
    "X = pd_data[0].iloc[:, :22]\n",
    "N, I = X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
